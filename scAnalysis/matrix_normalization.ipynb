{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b19517-4fd1-44a8-a426-a2b252a9cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm \n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "# set figure size for better visibility\n",
    "sc.settings.set_figure_params(dpi=100, frameon=False)\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59e558-fb49-4183-8afe-3e747a5e202a",
   "metadata": {},
   "source": [
    "## NORMALIZATION\n",
    "\n",
    "Using Pearson residuals (see paper https://doi.org/10.1186/s13059-019-1874-1)\n",
    "\n",
    "Uncouple poisson noise from technical issues from biological heterogeneity: handles the \"depth\" scaling and variance stabilization.\n",
    "\n",
    "Notes:\n",
    "\n",
    "1. We do NOT filter genes yet. The method needs most genes to fit the model.\n",
    "2. We perform this on the WHOLE dataset (all plates/conditions mixed).\n",
    "3. Might be needed to still need some extra correction for batch effects (Harmony / scVI). We will see this with the UMAP and mESC control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433734c0-32ca-4b88-90b7-1a734c5ba7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "--- MATRIX INSPECTION ---\n",
      "Data Sample: [1 0 3 0 1 3 1 0 1 1]\n",
      "Data Type: int64\n",
      "Physics Check Passed: Data represents discrete quanta (Integers).\n",
      "Raw counts saved to adata.layers['counts'].\n",
      "\n",
      "--- RUNNING NORMALIZATION ---\n",
      "computing analytic Pearson residuals on counts\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.02 GiB for an array with shape (3311, 244105) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- RUNNING NORMALIZATION ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# This creates the GLM model and calculates residuals\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43msc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexperimental\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize_pearson_residuals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Overdispersion parameter (100 is standard for UMI data)\u001b[39;49;00m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Clips extreme outliers (√N) to stabilize variance\u001b[39;49;00m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_values\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcounts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Explicitly tell it to use the raw counts layer we just saved\u001b[39;49;00m\n\u001b[32m     59\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNormalization Complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33madata.X now contains Pearson Residuals (Gaussian-like distribution).\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scanpy\\experimental\\pp\\_normalization.py:147\u001b[39m, in \u001b[36mnormalize_pearson_residuals\u001b[39m\u001b[34m(adata, theta, clip, check_values, layer, inplace, copy)\u001b[39m\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcomputing analytic Pearson residuals on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomputed_on\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    145\u001b[39m start = logg.info(msg)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m residuals = \u001b[43m_pearson_residuals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m settings_dict = \u001b[38;5;28mdict\u001b[39m(theta=theta, clip=clip, computed_on=computed_on)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scanpy\\experimental\\pp\\_normalization.py:74\u001b[39m, in \u001b[36m_pearson_residuals\u001b[39m\u001b[34m(x, theta, clip, check_values, copy)\u001b[39m\n\u001b[32m     71\u001b[39m     sums_cells = np.sum(x, axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     72\u001b[39m     sum_total = np.sum(sums_genes)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m mu = np.array(\u001b[43msums_cells\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43msums_genes\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43msum_total\u001b[49m)\n\u001b[32m     75\u001b[39m diff = np.array(x - mu)\n\u001b[32m     76\u001b[39m residuals = diff / np.sqrt(mu + mu**\u001b[32m2\u001b[39m / theta)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 6.02 GiB for an array with shape (3311, 244105) and data type float64"
     ]
    }
   ],
   "source": [
    "# --- LOAD DATA ---\n",
    "print(\"Loading data...\")\n",
    "adata = sc.read_h5ad(\"../data/data_filtered_raw.h5ad\")\n",
    "\n",
    "# --- DATA TYPE DIAGNOSTICS (Sanity Check) ---\n",
    "# We verify if the matrix contains integers (counts) or floats (already normalized?)\n",
    "\n",
    "if issparse(adata.X):\n",
    "    data_sample = adata.X.data[:10] # Look at first 10 non-zero elements\n",
    "else:\n",
    "    data_sample = adata.X[:10, :10].flatten()\n",
    "\n",
    "print(\"--- MATRIX INSPECTION ---\")\n",
    "print(f\"Data Sample: {data_sample}\")\n",
    "print(f\"Data Type: {adata.X.dtype}\")\n",
    "\n",
    "# CHECK 1: Are they already normalized? (Small numbers < 1)\n",
    "if np.any((data_sample > 0) & (data_sample < 1)):\n",
    "    print(\"CRITICAL ERROR: Data appears to be already normalized (values < 1 found).\")\n",
    "    print(\"STOP: Pearson Residuals require RAW INTEGER COUNTS.\")\n",
    "    # Stop execution here if this happens! You need to reload raw data.\n",
    "\n",
    "# CHECK 2: Are they floats looking like integers? (e.g. 5.0, 12.0)\n",
    "# We calculate the sum of fractional parts. Should be 0.\n",
    "if issparse(adata.X):\n",
    "    fractional_part = np.sum(adata.X.data % 1)\n",
    "else:\n",
    "    fractional_part = np.sum(adata.X % 1)\n",
    "\n",
    "if fractional_part == 0:\n",
    "    print(\"Physics Check Passed: Data represents discrete quanta (Integers).\")\n",
    "    \n",
    "    # Force casting to integer to satisfy the algorithm's strict requirements\n",
    "    # This changes 5.0 to 5, silencing the warning.\n",
    "    if adata.X.dtype != int:\n",
    "        print(\"Casting matrix from Float to Int...\")\n",
    "        adata.X = adata.X.astype(int)\n",
    "else:\n",
    "    print(\"WARNING: Data has non-zero fractional parts but > 1.\")\n",
    "    print(\"Did you apply some scaling? Pearson Residuals might be inaccurate.\")\n",
    "    # Usually we round to nearest integer if we trust the raw nature\n",
    "    adata.X = np.rint(adata.X).astype(int)\n",
    "\n",
    "# --- SAVE RAW STATE (Backup) ---\n",
    "# Before normalizing, we MUST save the raw counts.\n",
    "# 'counts' layer is the standard slot for this.\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "print(\"Raw counts saved to adata.layers['counts'].\")\n",
    "\n",
    "# --- NORMALIZATION (Hafemeister & Satija / Pearson Residuals) ---\n",
    "print(\"\\n--- RUNNING NORMALIZATION ---\")\n",
    "# This creates the GLM model and calculates residuals\n",
    "sc.experimental.pp.normalize_pearson_residuals(\n",
    "    adata, \n",
    "    theta=100,      # Overdispersion parameter (100 is standard for UMI data)\n",
    "    clip=True,      # Clips extreme outliers (√N) to stabilize variance\n",
    "    check_values=True,\n",
    "    layer=\"counts\"  # Explicitly tell it to use the raw counts layer we just saved\n",
    ")\n",
    "\n",
    "print(\"Normalization Complete.\")\n",
    "print(\"adata.X now contains Pearson Residuals (Gaussian-like distribution).\")\n",
    "print(f\"Range of new values: {adata.X.min():.2f} to {adata.X.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9181cb9-0e0e-4244-83d9-246ffa96ddbd",
   "metadata": {},
   "source": [
    "## PCA / UMAP\n",
    "\n",
    "INTERPRETATION:\n",
    "\n",
    "1. In the 'plate' coloring, mESC cluster is a mix of colors => ok\n",
    "2. Distinct islands of \"Plate 1 mESC\" and \"Plate 2 mESC\" => batch correction needed (e.g., Harmony, BBKNN, scVI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9df722-e849-41f1-930c-1b2f12b4ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DIMENSIONALITY REDUCTION ---\n",
    "\n",
    "# PCA (Principal Component Analysis)\n",
    "sc.tl.pca(adata, n_comps=30, svd_solver='arpack')\n",
    "\n",
    "# Calculate Neighbors (Graph construction)\n",
    "# k-NN graph in PCA space. Needed for UMAP/Clustering.\n",
    "sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30)\n",
    "\n",
    "# UMAP (Uniform Manifold Approximation and Projection)\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "# --- BATCH EFFECT VISUALIZATION ---\n",
    "# => THE \"mESC\" TEST\n",
    "#\n",
    "# Coloring by:\n",
    "# - Sample Type: To see if mESC cluster together away from Ectoderm\n",
    "# - Plate: To see if mESCs from Plate 1 overlap with mESCs from Plate 2\n",
    "\n",
    "sc.pl.umap(\n",
    "    adata, \n",
    "    color=['sample_type', 'plate', 'experiment'], \n",
    "    wspace=0.3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
